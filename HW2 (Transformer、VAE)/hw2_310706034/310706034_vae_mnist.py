# -*- coding: utf-8 -*-
"""dl 2_2  mnist code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13lO9JOL8mwZYT0sp1lX42mxjEZjsui-J
"""

import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt # plt 顯示圖片
import matplotlib.image as mpimg # mpimg 讀取圖片
from torchvision.utils import save_image, make_grid
from torchvision import datasets
from torchvision import transforms

# torch.autograd.set_detect_anomaly(True)
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(device)

"""# VAE Structure"""

class VAE(nn.Module):
    def __init__(self, input_size, hidden_size, feature_size):
        super(VAE, self).__init__()
        
        self.relu = nn.ReLU()
        self.sigmoid = nn.Sigmoid()
        # encoder
        self.encoder1 = nn.Linear(input_size, hidden_size)
        self.encoder2 = nn.Linear(hidden_size, feature_size * 2)
        # decoder
        self.decoder1 = nn.Linear(feature_size, hidden_size)
        self.decoder2 = nn.Linear(hidden_size, input_size)
        
    def encoder(self, x):
        hidden = self.encoder2(self.relu(self.encoder1(x)))
        return hidden.view(-1, 2, feature_size)
    
    def reparameterize(self, mu, log_var):
        std = torch.exp(0.5*log_var)
        epsilon = torch.randn_like(std)
        sample = mu + (epsilon * std)
        return sample
    
    def decoder(self, x):
        hidden = self.sigmoid(self.decoder2(self.relu(self.decoder1(x))))
        return hidden
    
    def cal_loss(self, loss, mu, logvar):
        BCE = loss 
        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
        return BCE, KLD
        
    def forward(self, x):
        out = self.encoder(x)
        mu = out[:, 0, :]
        log_var = out[:, 1, :]
        z = self.reparameterize(mu, log_var)
        reconst = self.decoder(z).type(torch.float32)
        return reconst, mu, log_var, z
    
    def plot_figure_loss(self, loss):
        plt.figure(figsize=(6.4, 4.8))
        plt.plot(loss, label='Training')
        plt.xlabel('Epochs')
        plt.ylabel('Nagetive ELBO')
        
        plt.show()

"""# Data Preproccessing"""

def toDataLoader(image, label, batch_size, threshold):
    for i, img in enumerate(image):
        image[i] = np.where(img <= threshold, 0, 1)
    image_size = image.shape[1]
    image_type = 1
    image_shape = image.reshape((image.shape[0], image.shape[1]*image.shape[2]))
    input_size = image_shape.shape[1]
    train_image = torch.tensor(image_shape)
    train_label = torch.tensor(label)
    train_tensor = torch.utils.data.TensorDataset(train_image, train_label)
    train_loader = torch.utils.data.DataLoader(train_tensor, batch_size=batch_size, shuffle=False)
    return train_loader, image_size, image_type, input_size

def plot_synthesized(model, train_loader, image_type, image_size, scale=None, n=11):
    
    rand = torch.randint(0, len(train_loader.dataset), (2, )).to(device)
    rand_x = train_loader.dataset[rand[0]][0].type(torch.float32).to(device)
    rand_y = train_loader.dataset[rand[1]][0].type(torch.float32).to(device)
    
    _, _, _, x_z = model(rand_x)
    _, _, _, y_z = model(rand_y)
    synTensor = torch.zeros((n, image_type, image_size, image_size))
    grid_x = np.linspace(0.0, 1.0, n)
    for i, xi in enumerate(grid_x):
        z_sample = x_z*xi + y_z*(1-xi)
        reconstr_syn = model.decoder(z_sample).view(-1, image_type, image_size, image_size)    # (n, 3, 64, 64)
        synTensor[i, :, :, :] = reconstr_syn
    if scale == None:
        save_image(synTensor.view(-1, image_type, image_size, image_size), 'mnist_synthesized.png', nrow=n)
    else:
        save_image(synTensor.view(-1, image_type, image_size, image_size), 'mnist_synthesized_{}.png'.format(scale), nrow=n)

"""# Fit Model"""

def fit_model(train_loader, image_size, image_type, input_size, epoch=10, batch_size=64, LR=0.001, scale=None):
    VAE_model = VAE(input_size, hidden_size, feature_size).to(device)
    optimizer = optim.Adam(VAE_model.parameters(), lr=LR)
    criterion = nn.BCELoss(reduction='sum')
    
    train_lossList = []
    for ep in range(epoch):
        print('epoch: ', ep+1)
        train_error = 0.0
        ### train
        VAE_model.train()
        for i, data in enumerate(train_loader):
            train_X, train_y = data
            train_X = train_X.type(torch.float32).to(device)
            if train_X.size(0) == 64:
                origin_image = train_X
            
            optimizer.zero_grad()
            train_reconst, train_mu, train_logvar, train_z = VAE_model(train_X)
            train_bceLoss = criterion(train_reconst, train_X)
            train_BCE, train_KLD = VAE_model.cal_loss(train_bceLoss, train_mu, train_logvar)
            if scale == None:
                train_loss = train_BCE + train_KLD
            else:
                train_loss = train_BCE + 1 / (scale+0.00001) * train_KLD
            # train_loss = train_BCE + train_KLD
            train_loss.backward()
            optimizer.step()
            train_error += train_loss.item()
        
        train_losses = train_error / len(train_loader.dataset)
        print('train_loss: ', train_losses)
        train_lossList.append(train_losses)
        
        # ### 輸出每回 epoch 最後一個 batch_size=64 的圖
        # VAE_model.eval()
        # with torch.no_grad():
        #     const_image, train_mu, train_logvar, train_z = VAE_model(train_X)
        #     train_bceLoss = criterion(const_image, train_X)
        #     train_BCE, train_KLD = VAE_model.cal_loss(train_bceLoss, train_mu, train_logvar)
        #     # (B x C x H x W)
        #     concat_image = torch.cat([train_X.view(-1, image_type, image_size, image_size), const_image.view(-1, image_type, image_size, image_size)], dim=3)
        #     if scale == None:
        #         save_image(concat_image, 'minst_{}.png'.format(ep))
        #     else:
        #         save_image(concat_image, 'minst_{}_{}.png'.format(ep, scale))

    
    ### plot loss figure
    VAE_model.plot_figure_loss(train_lossList)
    
    ### output the reconstruction/sample image
    VAE_model.eval()
    with torch.no_grad():
        const_image, _, _, _ = VAE_model(origin_image)
        if scale == None:
            save_image(origin_image.view(-1, image_type, image_size, image_size), 'mnist_origin.png')
            save_image(const_image.view(-1, image_type, image_size, image_size), 'mnist_reconst.png')
        else:
            save_image(origin_image.view(-1, image_type, image_size, image_size), 'mnist_origin_{}.png'.format(scale))
            save_image(const_image.view(-1, image_type, image_size, image_size), 'mnist_reconst_{}.png'.format(scale))
        
        sample = torch.randn(batch_size, feature_size).to(device)
        sample_image = VAE_model.decoder(sample).view(-1, image_type, image_size, image_size)
        if scale == None:
            save_image(sample_image.view(-1, image_type, image_size, image_size), 'mnist_sample.png')
        else:
            save_image(sample_image.view(-1, image_type, image_size, image_size), 'mnist_sample_{}.png'.format(scale))
    
    ### output the synthesized image
    plot_synthesized(VAE_model, train_loader, image_type, image_size, scale)

"""# Train and Result"""

threshold = 127
epoch = 10
batch_size = 64
LR = 0.001

hidden_size = 512
feature_size = 16


with np.load('./TibetanMNIST.npz') as mnist:
    image = mnist['image']
    label = mnist['label']


train_loader, image_size, image_type, input_size = toDataLoader(image, label, batch_size, threshold)
fit_model(train_loader, image_size, image_type, input_size, epoch, batch_size, LR)


for scale in [25, 75]:
    print('scale: ', scale)
    fit_model(train_loader, image_size, image_type, input_size, epoch, batch_size, LR, scale)